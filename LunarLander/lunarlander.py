# -*- coding: utf-8 -*-
"""LunarLander.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QVHCYFPvPLM1Q1soKIIw67JO1TrdFn5e

###Requirements
"""

!apt install swig cmake

!pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt

!sudo apt-get update
!sudo apt-get install -y python3-opengl
!apt install ffmpeg
!apt install xvfb
!pip3 install pyvirtualdisplay

import os
os.kill(os.getpid(),9)

# Virtual display
from pyvirtualdisplay import Display

virtual_display = Display(visible=0, size=(1400, 900))
virtual_display.start()

import gymnasium

from huggingface_sb3 import load_from_hub, package_to_hub
from huggingface_hub import notebook_login # To log to our Hugging Face account to be able to upload models to the Hub.

from stable_baselines3 import PPO
from stable_baselines3.common.env_util import make_vec_env
from stable_baselines3.common.evaluation import evaluate_policy
from stable_baselines3.common.monitor import Monitor

"""###Gymnasium"""

import gymnasium as gym
env = gym.make('LunarLander-v2')

observation, info  = env.reset()

for _ in range(20):
  action = env.action_space.sample()
  print("Action taken: ",action)

  observation,reward,terminated,truncated,info = env.step(action)

  if terminated or truncated:
    print("Environment is reset")
    observation,info = env.reset()

env.close()

env = gym.make("LunarLander-v2")
env.reset()
print("___observation space___")
print("Observation Space Shape",env.observation_space.shape)
print("Sample Observation",env.observation_space.sample())

print("Action Space\n")
print("Action space shape:",env.action_space.n)
print("Action space sample: ",env.action_space.sample())

#Create the environment
env = make_vec_env("LunarLander-v2",n_envs=16)

"""###Create Model"""

model = PPO(
    policy = "MlpPolicy",
    env = env,
    n_steps = 1024,
    batch_size = 64,
    n_epochs=4,
    gamma=0.999,
    gae_lambda=0.98,
    ent_coef=0.01,
    verbose=1
)

model.learn(total_timesteps=1000000)
model_name = "ppo-LunarLander-v2"
model.save(model_name)

eval_env = Monitor(gym.make("LunarLander-v2", render_mode='rgb_array'))
mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)
print(f"mean_reward={mean_reward:.2f} +/- {std_reward}")

notebook_login()
!git config --global credential.helper store

import gymnasium as gym

from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.env_util import make_vec_env
from huggingface_sb3 import package_to_hub

env_id = "LunarLander-v2"

model_architecture = "PPO"

repo_id = "Caraxes-44/ppo-LunarLander-v2"

commit_message = "Uploaded LunarLander trained agent"

eval_env = DummyVecEnv([lambda: Monitor(gym.make(env_id, render_mode="rgb_array"))])

package_to_hub(
    model=model,
    model_name=model_name,
    model_architecture=model_architecture,
    env_id=env_id,
    eval_env=eval_env,
    repo_id=repo_id,
    commit_message=commit_message,
)

